{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display"
   ],
   "id": "821f1ad367412610"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "llm"
   ],
   "id": "4424ee0478dfa3e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ],
   "id": "b53501ab665e2406"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    improved_joke: str\n",
    "    final_joke: str"
   ],
   "id": "47414bc3dd1237f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Nodes\n",
    "def generate_joke(state: State) -> dict[str, str]:\n",
    "    \"\"\"First LLM call to generate initial joke\"\"\"\n",
    "\n",
    "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "\n",
    "def check_punchline(state: State) -> str:\n",
    "    \"\"\"Gate function to check if the joke has a punchline\"\"\"\n",
    "\n",
    "    # Simple check - does the joke contain \"?\" or \"!\"\n",
    "    if \"?\" in state[\"joke\"] or \"!\" in state[\"joke\"]:\n",
    "        return \"Pass\"\n",
    "    return \"Fail\"\n",
    "\n",
    "\n",
    "def improve_joke(state: State) -> dict[str, str]:\n",
    "    \"\"\"Second LLM call to improve the joke\"\"\"\n",
    "\n",
    "    msg = llm.invoke(f\"Make this joke funnier by adding wordplay: {state['joke']}\")\n",
    "    return {\"improved_joke\": msg.content}\n",
    "\n",
    "\n",
    "def polish_joke(state: State) -> dict[str, str]:\n",
    "    \"\"\"Third LLM call for final polish\"\"\"\n",
    "\n",
    "    msg = llm.invoke(f\"Add a surprising twist to this joke: {state['improved_joke']}\")\n",
    "    return {\"final_joke\": msg.content}\n"
   ],
   "id": "87652502d1c8bba8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Build workflow\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "workflow.add_node(\"improve_joke\", improve_joke)\n",
    "workflow.add_node(\"polish_joke\", polish_joke)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "workflow.add_edge(START, \"generate_joke\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_joke\", check_punchline, {\"Fail\": \"improve_joke\", \"Pass\": END}\n",
    ")\n",
    "workflow.add_edge(\"improve_joke\", \"polish_joke\")\n",
    "workflow.add_edge(\"polish_joke\", END)"
   ],
   "id": "c0125b1dc10e9b01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compile\n",
    "chain = workflow.compile()\n",
    "\n",
    "# Show workflow\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ],
   "id": "257d7dee549645f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Invoke\n",
    "state = chain.invoke({\"topic\": \"cats\"})\n",
    "print(\"Initial joke:\")\n",
    "print(state[\"joke\"])\n",
    "print(\"\\n--- --- ---\\n\")\n",
    "if \"improved_joke\" in state:\n",
    "    print(\"Improved joke:\")\n",
    "    print(state[\"improved_joke\"])\n",
    "    print(\"\\n--- --- ---\\n\")\n",
    "\n",
    "    print(\"Final joke:\")\n",
    "    print(state[\"final_joke\"])\n",
    "else:\n",
    "    print(\"Joke failed quality gate - no punchline detected!\")"
   ],
   "id": "19e5a745befb9f3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# My Solution",
   "id": "b291279a3619fc3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## AI Agents\n",
    "\n",
    "- Orchestrator\n",
    "- Software Architect\n",
    "    - Code formatters - code styling, spacing, identation\n",
    "    - Refactor Tools: Suggest code improvements & restructuring\n",
    "        - Functions are too long\n",
    "        - Duplicate code detection \n",
    "- Security Engineer\n",
    "    - Security scanner\n",
    "        - Hardcoded secrets,\n",
    "        - SQL injection patterns \n",
    "    - CVE database\n",
    "        - CVE API\n",
    "        - Detect top 10 attacks\n",
    "        - GitHub Advisory Database API\n",
    "    - Depracated tools and uses\n",
    "        - Check changes in requirements, package.json, check if they are outdated \n",
    "- Performance Engineer\n",
    "    - Profiling tool: nested loops, inefficient queries\n",
    "    - Benchmark tools: cyclomatic complexity, nesting depth\n",
    "- Tech Writer\n",
    "    - Check for missing docstrings/comments \n",
    "    - Generate Docs from code\n",
    "- Tech lead\n",
    "    - Merge tools\n",
    "    - Notification tool\n",
    "\n",
    "**Optional**\n",
    "\n",
    "- Code Reviewer\n",
    "    - AST parser\n",
    "    - Linting Tools"
   ],
   "id": "960f6c95fb2ec5f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Tools",
   "id": "ea992b1edacfaf02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b16014618d2c94b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Agents",
   "id": "1f6e04dc73321666"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "orchastrator = create_react_agent(llm, tools=[])\n",
    "security_agent = create_react_agent(llm, tools=[])\n",
    "software_architect_agent = create_react_agent(llm, tools=[])\n",
    "performance_agent = create_react_agent(llm, tools=[])\n",
    "tech_writer_agent = create_react_agent(llm, tools=[])\n",
    "tech_lead = create_react_agent(llm, tools=[])\n",
    "software_engineer_lead = create_react_agent(llm, tools=[])"
   ],
   "id": "553c39d9204ed94b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# def check_packages(): pass\n",
    "\n",
    "# sub_graph = StateGraph(State)\n",
    "# sub_graph.add_node(\"Security Engineer\", security_agent)\n",
    "# sub_graph.add_node(\"Check Packages\", check_packages)\n",
    "# sub_graph.add_edge(START, \"Security Engineer\")\n",
    "# sub_graph.add_edge(\"Security Engineer\", \"Check Packages\")\n",
    "# sub_graph.add_edge(\"Check Packages\", END)\n",
    "# sub_graph = sub_graph.compile()\n",
    "\n"
   ],
   "id": "f9ae496fb0aaeda0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"Project Manager\", orchastrator)\n",
    "workflow.add_node(\"Security Engineer\", security_agent)\n",
    "workflow.add_node(\"Software Architect\", software_architect_agent)\n",
    "workflow.add_node(\"Performance Engineer\", performance_agent)\n",
    "workflow.add_node(\"Technical Writer\", tech_writer_agent)\n",
    "workflow.add_node(\"Tech Lead\", tech_lead)\n",
    "workflow.add_node(\"Software Engineer\", software_engineer_lead)\n",
    "\n",
    "\n",
    "# Add edges to connect nodes\n",
    "workflow.add_edge(START, \"Project Manager\")\n",
    "workflow.add_edge(\"Project Manager\", \"Security Engineer\")\n",
    "workflow.add_edge(\"Project Manager\", \"Software Architect\")\n",
    "workflow.add_edge(\"Project Manager\", \"Performance Engineer\")\n",
    "workflow.add_edge(\"Project Manager\", \"Technical Writer\")\n",
    "\n",
    "\n",
    "\n",
    "workflow.add_edge(\"Security Engineer\", \"Tech Lead\")\n",
    "workflow.add_edge(\"Software Architect\", \"Tech Lead\")\n",
    "workflow.add_edge(\"Performance Engineer\", \"Tech Lead\")\n",
    "workflow.add_edge(\"Technical Writer\", \"Tech Lead\")\n",
    "\n",
    "workflow.add_edge(\"Tech Lead\", END)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"Tech Lead\", approve_changes, {\"Rejected Merge\": \"Software Engineer\", \"Approved Merge\": END}\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"Software Engineer\", END)\n"
   ],
   "id": "2f1ab16fd2f0279c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def approve_changes():\n",
    "    pass"
   ],
   "id": "f676c5bb68b0b22a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compile\n",
    "chain = workflow.compile()\n",
    "\n",
    "# Show workflow\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ],
   "id": "e3b12d9cfbb05e0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "search_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "\n",
    "def search_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "web_scraper_agent = create_react_agent(llm, tools=[scrape_webpages])\n",
    "\n",
    "\n",
    "def web_scraper_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = web_scraper_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"web_scraper\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "research_supervisor_node = make_supervisor_node(llm, [\"search\", \"web_scraper\"])"
   ],
   "id": "fa5be822fb6c14c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
